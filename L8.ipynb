{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking1 在CTR点击率预估中，使用GBDT+LR的原理是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 原本问题\n",
    "      样本数量大，点击率预估模型中的训练样本可达上亿级别\n",
    "      学习能力有限，以往的CTR预估采用LR模型，LR是线性模型，虽然速度较快，但是学习能力有限\n",
    "     人工成本高，为了更好的进行特征提取，提升LR的学习能力，需要采用人工特征工程，即通过人工方式找到有区分度的特征、特征组合。对人的要求高，时间成本高\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 要解决的问题：自动发现有效的特征及特征组合，弥补人工经验不足，缩短LR实验周期\n",
    "        通过GBDT将特征进行组合，然后传入给线性分类器\n",
    "        LR对GBDT产生的输入数据进行分类\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking2 Wide & Deep的模型结构是怎样的，为什么能通过具备记忆和泛化能力（memorization and generalization）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 结构\n",
    "    线性模型和深度神经网络DNN的组合，该模型结合了线性模型的记忆能力和DNN模型的泛化能力，在训练过程中同时优化两个模型的参数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 记忆和泛化能力\n",
    "    线性模型的分类效果比较好，使用线性模型对已有数据进行分类，就是具备记忆能力\n",
    "    DNN模型泛化能力较强，可以探索一些没有的特征组合，因此具备泛化能力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking3 在CTR预估中，使用FM与DNN结合的方式，有哪些结合的方式，代表模型有哪些？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 两种结合方式\n",
    "    一种是并行结构，将FM和DNN分开计算，代表模型有DeepFM等。\n",
    "    一种是串行架构，将FM的结果作为DNN的输入，代表模型有NFM等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking4 Surprise工具中的baseline算法原理是怎样的？BaselineOnly和KNNBaseline有什么区别？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### baseline\n",
    "    是基于统计的基准预测线打分，评分计算公式为：所有打分的均值+用户对整体的偏差+商品对整体的偏差。考虑的比较细致，因为有人倾向于打高分，也有人倾向于打低分，商品同理，商品好打分整体也会偏高。考虑了系统自身，用户自身，和商品自身。相对来说，个性化程度较高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 区别\n",
    "    KNNBaseline和BaselineOnly的思想类似，但是具体实现不一样。BaselineOnly评分为三部分之和：所有打分的均值+用户对整体的偏差+商品对整体的偏差。而KNNBaseline是在使用其他用户的评分的时候把其他用户对整体的偏差减掉，在计算完相似度之后，在最后加上该用户对整体的偏差。相对其他基于邻域的协同过滤算法，更为细致，个性化程度更好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking5 GBDT和随机森林都是基于树的算法，它们有什么区别？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GBDT \n",
    "    GBDT算法全名是Gradient Boosting Decision Tree，是Boosting家族的成员，将弱学习器集成为强学习器获得较为良好的性能。GBDT每次迭代都使用上一次的残差进行计算。最后将每次迭代得到的结果累加起来就是最终的结果。GDBT只有回归树组成，GBDT必须串行，因为用到上一棵树的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RF\n",
    "    属于Bagging一族，通过自助采样的方法生成众多并行式的分类器，通过“少数服从多数”的原则来确定最终的结果。\n",
    "    组成随机森林的树可以是分类树，也可以是回归树。随机森林的树可以并行生成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking6 基于邻域的协同过滤都有哪些算法，请简述原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 算法：\n",
    "    knns.KNNBasic\n",
    "    knns.KNNWithMeans\n",
    "    knns.KNNWithZScore\n",
    "    knns.KNNBaseline\n",
    "    等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 区别  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### knns.KNNBasic\n",
    "        可以用作基于user的协同过滤，也可以用作基于item协同过滤。其中userCF通过计算用户之间相似度和其他用户对某item的打分的乘积的累加和，再除以用户之间的相似度，可以预测该用户对某item的评分。itemCF同理。   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  knns.KNNWithMeans\n",
    "        在knnBasic的基础上，计算评分的时候减去了其他用户评分的均值，在最终评分的时候又加了该用户评分的均值上去，相比上一个更加突出了对用户个性化的评分。\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### knns.KNNWithZScore\n",
    "        在KNNWithMeans的基础上，将均值做归一化处理，变为正态分布。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### knns.KNNBaseline\n",
    "    KNNBaseline和BaselineOnly的思想类似。考虑了用户对整体偏差。KNNBaseline是在使用其他用户的评分的时候把其他用户对整体的偏差减掉，在计算完相似度之后，在最后加上该用户对整体的偏差。相对其他基于邻域的协同过滤算法，更为细致，个性化程度更好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action1 使用Wide&Deep模型对movielens进行评分预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 详情见 \n",
    "    MovieLens_NFM.ipynb,\n",
    "    Movielens_WDL.ipynb\n",
    "    MovieLens_sample_NFM.ipynb\n",
    "    Movielens_sample_WDL.ipynb\n",
    "文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action2 使用基于邻域的协同过滤（KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline中的任意一种）对MovieLens数据集进行协同过滤，采用k折交叉验证(k=3)，输出每次计算的RMSE, MAE5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 详情见\n",
    "    KNNWithMeans.ipynb\n",
    "    KNNBasic.ipynb\n",
    "    KNNWithMeans.ipynb\n",
    "    KNNBaseline\n",
    "文件"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
